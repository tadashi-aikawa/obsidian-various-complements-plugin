import { suggestCh } from "./replacer";
import { createTokenizer } from "./tokenizer/tokenizer";
import { TokenizeStrategy } from "./tokenizer/TokenizeStrategy";

// Emoji uses 2 indexes (It means that "ðŸ˜€a".indexOf("a") is not 1, but 2)
describe.each`
  tokenizerStrategy            | currentLineUntilCursor       | word                  | contextStartCh | expected
  ${TokenizeStrategy.DEFAULT}  | ${"aa bb c"}                 | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.DEFAULT}  | ${"aa bb c"}                 | ${"AA bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.DEFAULT}  | ${"AA bb c"}                 | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.DEFAULT}  | ${"ðŸ˜€aa bb c"}               | ${"aa bb ccc"}        | ${8}           | ${5}
  ${TokenizeStrategy.DEFAULT}  | ${"aa bb c"}                 | ${"ðŸ˜€aa bb ccc"}      | ${6}           | ${0}
  ${TokenizeStrategy.DEFAULT}  | ${"aa bb ccc"}               | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.DEFAULT}  | ${"zz bb ccc"}               | ${"aa bb ccc"}        | ${6}           | ${3}
  ${TokenizeStrategy.DEFAULT}  | ${"zz yy ccc"}               | ${"aa bb ccc"}        | ${6}           | ${6}
  ${TokenizeStrategy.DEFAULT}  | ${"aa bb cc bb"}             | ${"aa bb ccc"}        | ${9}           | ${9}
  ${TokenizeStrategy.JAPANESE} | ${"aa bb c"}                 | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"aa bb c"}                 | ${"AA bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"AA bb c"}                 | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"ðŸ˜€aa bb c"}               | ${"aa bb ccc"}        | ${8}           | ${2}
  ${TokenizeStrategy.JAPANESE} | ${"aa bb c"}                 | ${"ðŸ˜€aa bb ccc"}      | ${6}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"aa bb ccc"}               | ${"aa bb ccc"}        | ${6}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"zz bb ccc"}               | ${"aa bb ccc"}        | ${6}           | ${3}
  ${TokenizeStrategy.JAPANESE} | ${"zz yy ccc"}               | ${"aa bb ccc"}        | ${6}           | ${6}
  ${TokenizeStrategy.JAPANESE} | ${"aa bb cc bb"}             | ${"aa bb ccc"}        | ${9}           | ${9}
  ${TokenizeStrategy.JAPANESE} | ${"æ—§å¸‚è¡—"}                  | ${"ã‚¤ãƒ¼ãƒ‡ã‚£ã‚¹æ—§å¸‚è¡—"} | ${0}           | ${0}
  ${TokenizeStrategy.JAPANESE} | ${"ã“ã‚Œã‹ã‚‰è¡Œãã®ã¯æ—§å¸‚è¡—"}  | ${"ã‚¤ãƒ¼ãƒ‡ã‚£ã‚¹æ—§å¸‚è¡—"} | ${0}           | ${8}
  ${TokenizeStrategy.JAPANESE} | ${"ã“ã‚Œã‹ã‚‰è¡Œãã®ã¯ æ—§å¸‚è¡—"} | ${"ã‚¤ãƒ¼ãƒ‡ã‚£ã‚¹æ—§å¸‚è¡—"} | ${9}           | ${9}
`(
  "suggestCh",
  ({
    tokenizerStrategy,
    currentLineUntilCursor,
    word,
    contextStartCh,
    expected,
  }) => {
    test(`suggestCh(${tokenizerStrategy.name}, ${currentLineUntilCursor}, ${word}, ${contextStartCh}) = ${expected}`, () => {
      expect(
        suggestCh(
          createTokenizer(tokenizerStrategy),
          currentLineUntilCursor,
          word,
          contextStartCh
        )
      ).toBe(expected);
    });
  }
);
